import pickle
import numpy as np
from collections import Counter
from copy import deepcopy
import re
import pdb
import matplotlib.pyplot as plt
import numpy.random as nrand
import model2_helpers

print('*************** Training IBM Model 1 ***************')
totalSteps = 10
eng_dict = pickle.load(open("../englishDict.dict",'r'))
french_dict = pickle.load(open("../frenchDict.dict",'r'))
eng_sent = [];
french_sent = [];

lengthsFr = [];
lengthsEn = [];

with open("../CleanedFrench1000.txt", "r") as fp:
	for x in fp:
	    xTemp = re.sub('[\n]', '', x)
            words = xTemp.split()
            french_sent.append(words)
            lengthsFr.append(len(words))

with open("../CleanedEnglish1000.txt", "r") as fp:
	for x in fp:
	    xTemp = re.sub('[\n]', '', x)
            words = xTemp.split()
            eng_sent.append(words)
            lengthsEn.append(len(words))
    
#count_matrix = np.zeros((len(eng_dict),len(french_dict)))*(1.0/(len(eng_dict)*len(french_dict)));

translation_matrix = np.ones((len(eng_dict),len(french_dict)))*(1.0/(len(eng_dict)*len(french_dict)));
alignment_matrix = {}

for i in range(8):
    for j in range(8):

        if i < 7 and j < 7:
            alignment_matrix[(i,j)] = np.ones(((i+1)*5,(j+1)*5))*0.01
        elif i < 7 and j == 7:
            alignment_matrix[(i,j)] = np.ones(((i+1)*5,50))*0.01
        elif i == 7 and j < 7:
            alignment_matrix[(i,j)] = np.ones((50, (i+1)*5))*0.01
        else:
            alignment_matrix[(i,j)] = np.ones((50,50))*0.01
            
lambda_norm = np.zeros((len(eng_dict)))
count_matrix = np.zeros((len(eng_dict),len(french_dict)))

#plt.plot(lengthsEn, lengthsFr, 'ro')
fit = np.polyfit(lengthsEn, lengthsFr, 1)
lengthsPred = []
for i in lengthsEn:
    lengthsPred.append(int(np.random.normal(i*fit[0],5)))

#plt.plot(lengthsEn, lengthsPred, 'g.')
#plt.show()

with open('../FitParams2.txt', 'wb') as fp:
    fp.write(str(fit[0]))
    fp.write('\n')
    fp.write('5')

print(' =====> Obtained the length distribution')

for step in range(totalSteps):

	print '=====> Iteration %d started'%(step)	
	# Updating counts 
        
	for i in range(len(eng_sent)):
                #pdb.set_trace()
		eng_words = eng_sent[i]
		french_words = french_sent[i]

		for e in eng_words:
		    for f in french_words:
		    	count_matrix[eng_dict[e]][french_dict[f]] += c_of_f_given_e(e, f, eng_words, french_words, eng_dict, french_dict, alignment_matrix, translation_matrix)
        
	# Updating t

    for englishWord in eng_dict:
		temp = 0
		for frenchWord in french_dict:
	#    	for index in range(len(eng_sent)):
	#    		if englishWord in eng_sent[index] and frenchWord in french_sent[index]:
			temp += count_matrix[eng_dict[englishWord]][french_dict[frenchWord]]
	        
                #pdb.set_trace()
                lambda_norm[eng_dict[englishWord]] = temp
		for frenchWord in french_dict:	
                    translation_matrix[eng_dict[englishWord]][french_dict[frenchWord]] = (count_matrix[eng_dict[englishWord]][french_dict[frenchWord]])/temp


print('=====> Finished training, saving data')
with open("../translationMatrix2.txt", "w") as fp:
	for i in range(len(translation_matrix)):
		for j in range(len(translation_matrix[i])):
			print >> fp, translation_matrix[i][j],
		print >> fp

print('=====> Saved data. Have a nice day!')
